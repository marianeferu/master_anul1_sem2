{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gTFkh1wdHMDT",
        "S0bYo5wcITTo",
        "4pKtVmexo8DH",
        "VG9Ns2W0K2o9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiPZs8hyHMMs"
      },
      "source": [
        "# Project Big Data Neferu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTFkh1wdHMDT"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKK3q_eMu_wi",
        "outputId": "a8366a12-43de-4f66-fe46-824890b687e4"
      },
      "source": [
        "! pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO5rlbLT05g4"
      },
      "source": [
        "import numpy as np\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql.functions import col\n",
        "import pyspark\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpykPcXTvUp6"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "try:\n",
        "    sc = SparkContext('local', 'Pyspark demo')\n",
        "except ValueError:\n",
        "    print('SparkContext already exists!')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "try:\n",
        "    spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()\n",
        "except ValueError:\n",
        "    print('SparkSession already exists!')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0bYo5wcITTo"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NAAKddyy2eE"
      },
      "source": [
        "df_ = spark.read.option('header', True).format('csv').load('/content/SolarPrediction.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3ASUngy2jz",
        "outputId": "f4da6dc0-8d68-4e1f-acf9-9e88c5a0e5b9"
      },
      "source": [
        "df_.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------------+--------+---------+-----------+--------+--------+----------------------+-----+-----------+----------+\n",
            "|  UNIXTime|                Data|    Time|Radiation|Temperature|Pressure|Humidity|WindDirection(Degrees)|Speed|TimeSunRise|TimeSunSet|\n",
            "+----------+--------------------+--------+---------+-----------+--------+--------+----------------------+-----+-----------+----------+\n",
            "|1475229326|9/29/2016 12:00:0...|23:55:26|     1.21|         48|   30.46|      59|                177.39| 5.62|   06:13:00|  18:13:00|\n",
            "|1475229023|9/29/2016 12:00:0...|23:50:23|     1.21|         48|   30.46|      58|                176.78| 3.37|   06:13:00|  18:13:00|\n",
            "|1475228726|9/29/2016 12:00:0...|23:45:26|     1.23|         48|   30.46|      57|                158.75| 3.37|   06:13:00|  18:13:00|\n",
            "|1475228421|9/29/2016 12:00:0...|23:40:21|     1.21|         48|   30.46|      60|                137.71| 3.37|   06:13:00|  18:13:00|\n",
            "|1475228124|9/29/2016 12:00:0...|23:35:24|     1.17|         48|   30.46|      62|                104.95| 5.62|   06:13:00|  18:13:00|\n",
            "|1475227824|9/29/2016 12:00:0...|23:30:24|     1.21|         48|   30.46|      64|                 120.2| 5.62|   06:13:00|  18:13:00|\n",
            "|1475227519|9/29/2016 12:00:0...|23:25:19|      1.2|         49|   30.46|      72|                112.45| 6.75|   06:13:00|  18:13:00|\n",
            "|1475227222|9/29/2016 12:00:0...|23:20:22|     1.24|         49|   30.46|      71|                122.97| 5.62|   06:13:00|  18:13:00|\n",
            "|1475226922|9/29/2016 12:00:0...|23:15:22|     1.23|         49|   30.46|      80|                101.18|  4.5|   06:13:00|  18:13:00|\n",
            "|1475226622|9/29/2016 12:00:0...|23:10:22|     1.21|         49|   30.46|      85|                141.87|  4.5|   06:13:00|  18:13:00|\n",
            "|1475226323|9/29/2016 12:00:0...|23:05:23|     1.23|         49|   30.47|      93|                120.55| 2.25|   06:13:00|  18:13:00|\n",
            "|1475226025|9/29/2016 12:00:0...|23:00:25|     1.21|         49|   30.47|      98|                144.19| 3.37|   06:13:00|  18:13:00|\n",
            "|1475225720|9/29/2016 12:00:0...|22:55:20|     1.22|         49|   30.47|      99|                 139.8| 6.75|   06:13:00|  18:13:00|\n",
            "|1475225419|9/29/2016 12:00:0...|22:50:19|     1.21|         50|   30.47|      99|                140.92| 2.25|   06:13:00|  18:13:00|\n",
            "|1475225131|9/29/2016 12:00:0...|22:45:31|     1.23|         50|   30.47|      99|                147.61| 5.62|   06:13:00|  18:13:00|\n",
            "|1475224823|9/29/2016 12:00:0...|22:40:23|     1.22|         50|   30.47|      99|                113.78|  4.5|   06:13:00|  18:13:00|\n",
            "|1475224519|9/29/2016 12:00:0...|22:35:19|     1.21|         50|   30.47|      99|                123.03|10.12|   06:13:00|  18:13:00|\n",
            "|1475224222|9/29/2016 12:00:0...|22:30:22|     1.22|         50|   30.47|      99|                173.73| 6.75|   06:13:00|  18:13:00|\n",
            "|1475223919|9/29/2016 12:00:0...|22:25:19|     1.22|         50|   30.47|      98|                 91.43| 6.75|   06:13:00|  18:13:00|\n",
            "|1475223622|9/29/2016 12:00:0...|22:20:22|      1.2|         50|   30.47|      98|                109.74| 6.75|   06:13:00|  18:13:00|\n",
            "+----------+--------------------+--------+---------+-----------+--------+--------+----------------------+-----+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nomj95yO3pLG"
      },
      "source": [
        "columns = ['UNIXTime', 'Data', 'Time', 'Radiation', 'Temperature', 'Pressure', 'Humidity','WindDirection(Degrees)','Speed', 'TimeSunRise','TimeSunSet']\n",
        "rows = df_.count()\n",
        "cnt = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14C7lJOl4A3m",
        "outputId": "f03febed-1e92-4e44-c768-5604a9b980d8"
      },
      "source": [
        "for index, column in enumerate(columns):\n",
        "\n",
        "    notNull = df_.filter(col(str(column)).isNotNull()).count()\n",
        "\n",
        "    if  notNull != rows:\n",
        "        print('There are '+str(rows - notNull)+' Null values in the date column')\n",
        "    else:\n",
        "        cnt += 1\n",
        "\n",
        "    if cnt != index+1:\n",
        "        print('There are not NULL values in the '+str(column)+' column')\n",
        "\n",
        "    elif cnt == len(columns):\n",
        "        print('There are not NULL values in the data frame')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are not NULL values in the data frame\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKh4K3bi6JNB"
      },
      "source": [
        "# Data\n",
        "\n",
        "split_col = pyspark.sql.functions.split(df_['Data'], '/')\n",
        "df_ = df_.withColumn('Month', split_col.getItem(0))\n",
        "df_ = df_.withColumn('Day', split_col.getItem(1))\n",
        "df_ = df_.withColumn('YearAux', split_col.getItem(2)) # year + time"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-MW9kDG0cki"
      },
      "source": [
        "# Time\n",
        "\n",
        "split_col = pyspark.sql.functions.split(df_['Time'], ':')\n",
        "df_ = df_.withColumn('Hour', split_col.getItem(0))\n",
        "df_ = df_.withColumn('Minute', split_col.getItem(1))\n",
        "df_ = df_.withColumn('Second', split_col.getItem(2))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwXYZfTZGsge"
      },
      "source": [
        "columns.append('Month')\n",
        "columns.append('Day')\n",
        "columns.append('Hour')\n",
        "columns.append('Minute')\n",
        "columns.append('Second')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piS94jsb6rPx"
      },
      "source": [
        "df = df_.select([column for column in columns if column not in ['Time', 'Data', 'YearAux', 'TimeSunRise', 'TimeSunSet', 'UNIXTime']])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GmDUfDy8l72",
        "outputId": "4e2b0cd7-905c-4c65-9490-bdc04ae55ba4"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----------+--------+--------+----------------------+-----+-----+---+----+------+------+\n",
            "|Radiation|Temperature|Pressure|Humidity|WindDirection(Degrees)|Speed|Month|Day|Hour|Minute|Second|\n",
            "+---------+-----------+--------+--------+----------------------+-----+-----+---+----+------+------+\n",
            "|     1.21|         48|   30.46|      59|                177.39| 5.62|    9| 29|  23|    55|    26|\n",
            "|     1.21|         48|   30.46|      58|                176.78| 3.37|    9| 29|  23|    50|    23|\n",
            "|     1.23|         48|   30.46|      57|                158.75| 3.37|    9| 29|  23|    45|    26|\n",
            "|     1.21|         48|   30.46|      60|                137.71| 3.37|    9| 29|  23|    40|    21|\n",
            "|     1.17|         48|   30.46|      62|                104.95| 5.62|    9| 29|  23|    35|    24|\n",
            "|     1.21|         48|   30.46|      64|                 120.2| 5.62|    9| 29|  23|    30|    24|\n",
            "|      1.2|         49|   30.46|      72|                112.45| 6.75|    9| 29|  23|    25|    19|\n",
            "|     1.24|         49|   30.46|      71|                122.97| 5.62|    9| 29|  23|    20|    22|\n",
            "|     1.23|         49|   30.46|      80|                101.18|  4.5|    9| 29|  23|    15|    22|\n",
            "|     1.21|         49|   30.46|      85|                141.87|  4.5|    9| 29|  23|    10|    22|\n",
            "|     1.23|         49|   30.47|      93|                120.55| 2.25|    9| 29|  23|    05|    23|\n",
            "|     1.21|         49|   30.47|      98|                144.19| 3.37|    9| 29|  23|    00|    25|\n",
            "|     1.22|         49|   30.47|      99|                 139.8| 6.75|    9| 29|  22|    55|    20|\n",
            "|     1.21|         50|   30.47|      99|                140.92| 2.25|    9| 29|  22|    50|    19|\n",
            "|     1.23|         50|   30.47|      99|                147.61| 5.62|    9| 29|  22|    45|    31|\n",
            "|     1.22|         50|   30.47|      99|                113.78|  4.5|    9| 29|  22|    40|    23|\n",
            "|     1.21|         50|   30.47|      99|                123.03|10.12|    9| 29|  22|    35|    19|\n",
            "|     1.22|         50|   30.47|      99|                173.73| 6.75|    9| 29|  22|    30|    22|\n",
            "|     1.22|         50|   30.47|      98|                 91.43| 6.75|    9| 29|  22|    25|    19|\n",
            "|      1.2|         50|   30.47|      98|                109.74| 6.75|    9| 29|  22|    20|    22|\n",
            "+---------+-----------+--------+--------+----------------------+-----+-----+---+----+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pKtVmexo8DH"
      },
      "source": [
        "# Column type conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VCTERhs7-j"
      },
      "source": [
        "cols = ['Radiation', 'Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed', 'Month', 'Day', 'Hour','Minute','Second']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n46G05Wfs8rS"
      },
      "source": [
        "#for column in cols:\n",
        "#    df.withColumn( column, col(column).cast('float'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z1AECLBv4pL"
      },
      "source": [
        "def isfloat(x):\n",
        "    try:\n",
        "        float(x)\n",
        "    except :\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "line1 = df.head(1)[0]\n",
        "\n",
        "df = df.select([c for c in df.columns if not isfloat(line1[c])] + [df[c].cast(\"float\").alias(c) for c in df.columns if isfloat(line1[c])])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG9Ns2W0K2o9"
      },
      "source": [
        "# Train Test Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6eG1UDDtbt6"
      },
      "source": [
        "train, test = df.randomSplit([0.7, 0.3], seed = 41)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTEcLNiruJ92"
      },
      "source": [
        "# Creating freatures assembler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW1ZeMR4uCkM"
      },
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=['Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed', 'Month', 'Day', 'Hour', 'Minute', 'Second'],\n",
        "    outputCol='Features')\n",
        "\n",
        "\n",
        "train_data = assembler.transform(train)\n",
        "test_data = assembler.transform(test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjS14nx1xK2N"
      },
      "source": [
        "train_data =  train_data.select([column for column in ['Features', 'Radiation']])\n",
        "test_data = test_data.select([column for column in ['Features', 'Radiation']])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uZw8nrRHYKf"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF_kRrT0NCZa",
        "outputId": "f1ce21a2-dbbc-44a6-d178-619e6409e36f"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(labelCol = 'Radiation', featuresCol = 'Features')\n",
        "lrModel = lr.fit(train_data)\n",
        "\n",
        "print(\"Coef: {} Intercept: {}\".format(lrModel.coefficients, lrModel.intercept))\n",
        "\n",
        "test_results = lrModel.evaluate(test_data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coef: [44.53853043903141,-388.82784507407104,0.5412385785935172,-0.2578308560088952,4.725503617551229,59.7150350458814,4.847068178981946,-7.522335552875352,0.00947306448028783,-1.4027697073140861] Intercept: 9134.169617105672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjXk9Y_a3a6e",
        "outputId": "e7c783e5-b5e1-4460-fdfa-cb668ae71e81"
      },
      "source": [
        "#Evaluation LR\n",
        "\n",
        "print(\"MAE: {}\".format(test_results.meanAbsoluteError))\n",
        "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
        "print(\"R2: {}\".format(test_results.r2))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 146.64277488396166\n",
            "MSE: 37048.48396611931\n",
            "R2: 0.6252107625484169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eum26c5e4u7B"
      },
      "source": [
        "#from pyspark.ml.regression import RandomForestRegressor\n",
        "#from pyspark.ml.evaluation import RegressionEvaluator\n",
        "#from pyspark.ml import Pipeline\n",
        "#from pyspark.ml.feature import VectorIndexer\n",
        "\n",
        "\n",
        "#rf = RandomForestRegressor(labelCol = 'Radiation', featuresCol = 'Features')\n",
        "#rfModel = rf.fit(train_data)\n",
        "\n",
        "#rfevaluator = RegressionEvaluator(predictionCol = \"Features\", labelCol = \"Radiation\", metricName = \"rmse\")\n",
        "\n",
        "#rfpredictions = rfModel.transform(test_data)\n",
        "\n",
        "#print( 'MAE:' ,rfevaluator.evaluate(rfpredictions))\n",
        "#featureIndexer = VectorIndexer(inputCol=\"Features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(train_data)\n",
        "\n",
        "##pipeline = Pipeline(stages = [featureIndexer, rf])\n",
        "\n",
        "#model = pipeline.fit(train_data)\n",
        "#predictions = model.transform(test_data)\n",
        "\n",
        "#evaluator = RegressionEvaluator(labelCol = 'Radiation', featuresCol = 'Features', metricName=\"rmse\")\n",
        "\n",
        "#rmse = evaluator.evaluate(predictions)\n",
        "#print(rmse)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwi7-AXS8kk0"
      },
      "source": [
        "#Evaluation RF\n",
        "\n",
        "#print(\"MAE: {}\".format(test_results_rf.meanAbsoluteError))\n",
        "#print(\"MSE: {}\".format(test_results_rf.meanSquaredError))\n",
        "#print(\"R2: {}\".format(test_results_rf#.r2))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUd7RLYy4uzx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Rzlagx4uh7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}